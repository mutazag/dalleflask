{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational ReAct Agent with Bing search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.160\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\users\\mutaza\\appdata\\roaming\\python\\python39\\site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show langchain\n",
    "\n",
    "# q: pip command to check if langchain is up to date\n",
    "# %pip list --outdated | grep langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/modules/agents/tools/examples/bing_search.html\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    \n",
    ")\n",
    "from langchain.schema import ( \n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "# import callbackmanager\n",
    "from langchain.callbacks.base import BaseCallbackManager as CallBackManager\n",
    "# from langchain.callbacks import \n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# get above env variables using os.environ.get and use provided values as defaults\n",
    "gpt4_endpoint = os.environ.get('gpt4_endpoint', 'https://lnc-eastus-openai.openai.azure.com/')\n",
    "gpt4_key = os.environ.get('gpt4_key', '121221')\n",
    "gpt4_region = os.environ.get('gpt4_region', 'eastus')\n",
    "gpt4_modelid_4k = os.environ.get('gpt4_modelid_4k', 'gpt-4-0314')\n",
    "gpt4_modelid_32k = os.environ.get('gpt4_modelid_32k', 'gpt-4-32k-0314')\n",
    "gpt4_api_version = os.environ.get('gpt4_api_version', '2023-03-15-preview')\n",
    "\n",
    "\n",
    "# get the above from os.environ.get and use provided values as defaults\n",
    "chatgpt_api_key = os.environ.get('chatgpt_api_key', '121212121212')\n",
    "chatgpt_region = os.environ.get('chatgpt_region', 'southcentralus')\n",
    "chatgpt_endpoint = os.environ.get('chatgpt_endpoint', 'https://magopenai.openai.azure.com/')\n",
    "chatgpt_api_version = os.environ.get('chatgpt_api_version', '2021-03-15-preview')\n",
    "\n",
    "\n",
    "# bing search settings: bing_search_url and bing_subscription_key\n",
    "bing_search_url = os.environ.get('bing_search_url', 'https://api.bing.microsoft.com/v7.0/search')\n",
    "bing_subscription_key = os.environ.get('bing_subscription_key', '121212121212')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "oai_api_key = os.environ.get('oai_api_key', '121212121212')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<b>Thai</b> recipes and <b>Thai</b> <b>food</b>. Despite the fact that <b>Thai</b> <b>food</b> uses many of the same core ingredients as other South East Asian countries – chilli, garlic, ginger, lemongrass, fish sauce, palm ...'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"BING_SUBSCRIPTION_KEY\"] = \"\"\n",
    "# os.environ[\"BING_SEARCH_URL\"] = \"\"\n",
    "\n",
    "from pprint import pprint\n",
    "from langchain.utilities import BingSearchAPIWrapper\n",
    "search = BingSearchAPIWrapper(\n",
    "    bing_search_url=bing_search_url, \n",
    "    bing_subscription_key=bing_subscription_key, \n",
    "    k=1\n",
    "\n",
    ")\n",
    "\n",
    "search.run(\"what are some good dinners to make this week, if i like thai food?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting Bing Search tool in an Agent\n",
    "\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/agents/agents/examples/chat_conversation_agent.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\\n\\nI'm doing great, thanks for asking!\"\n",
      "{'api_base': 'https://magopenai.openai.azure.com/',\n",
      " 'api_type': 'azure',\n",
      " 'api_version': '2023-03-15-preview',\n",
      " 'deployment_name': 'davinci',\n",
      " 'frequency_penalty': 0,\n",
      " 'logit_bias': {},\n",
      " 'max_tokens': 256,\n",
      " 'model_name': 'text-davinci-003',\n",
      " 'n': 1,\n",
      " 'presence_penalty': 0,\n",
      " 'request_timeout': None,\n",
      " 'temperature': 0.0,\n",
      " 'top_p': 1}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "# openai.api_key = gpt4_key\n",
    "# openai.api_base = gpt4_endpoint\n",
    "\n",
    "# openai.api_type = \"azure\"\n",
    "# openai.api_version = gpt4_api_version\n",
    "\n",
    "\n",
    "azure_llm = AzureOpenAI(\n",
    "    deployment_name='davinci', \n",
    "    model_name='text-davinci-003', \n",
    "    openai_api_key=chatgpt_api_key,\n",
    "    # openai_api_endpoint=chatgpt_endpoint,\n",
    "    model_kwargs={\n",
    "        \"api_base\": chatgpt_endpoint, \n",
    "        \"api_type\": \"azure\", \n",
    "        \"api_version\": chatgpt_api_version,\n",
    "    },\n",
    "    temperature=0,\n",
    "\n",
    "    verbose=True)\n",
    "\n",
    "prompt = \"Hello, I am a chatbot. How are you today?\"\n",
    "pprint(azure_llm(prompt))\n",
    "pprint(azure_llm._identifying_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Apr 23, 2023 9:00pm. (49 images) Sweet, salty, sour and spicy, <b>Thai</b> food hits all the right notes and then some. There are fragrant soups and <b>Thai</b> curries to savour, and noodles swimming in broth or stir-fried with a touch of heat. You&#39;ll recognise some classics such as chicken green curry and papaya salad, but have a crack at other less ...'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run('what is a good thai recipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "from langchain.agents.load_tools import _get_llm_math, _get_bing_search\n",
    "\n",
    "\n",
    "tools = [\n",
    "    _get_bing_search(bing_subscription_key=bing_subscription_key, bing_search_url=bing_search_url, k=1),\n",
    "]\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"search\",\n",
    "#         func=search.run,\n",
    "#         description=\"useful for when you need to ask with search\"\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# self_ask_with_search = initialize_agent(tools, azure_llm, agent=AgentType.SELF_ASK_WITH_SEARCH, verbose=True)\n",
    "# self_ask_with_search.run(\"Who is the PM of australia, is he in a relationship, and who are the current and previous partners, and how long have they been together\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Bing Search',\n",
       " 'description': 'A wrapper around Bing Search. Useful for when you need to answer questions about current events. Input should be a search query.',\n",
       " 'args_schema': None,\n",
       " 'return_direct': False,\n",
       " 'verbose': False,\n",
       " 'callbacks': None,\n",
       " 'callback_manager': None,\n",
       " 'api_wrapper': {'bing_subscription_key': '0058d1f5e71c49b6ae96fc3155db5789',\n",
       "  'bing_search_url': 'https://api.bing.microsoft.com/v7.0/search',\n",
       "  'k': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools, \n",
    "    azure_llm, \n",
    "    memory=memory, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    # return_intermediate_steps=True,\n",
    "    verbose=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_memory': {'messages': []},\n",
       " 'output_key': None,\n",
       " 'input_key': None,\n",
       " 'return_messages': True,\n",
       " 'human_prefix': 'Human',\n",
       " 'ai_prefix': 'AI',\n",
       " 'memory_key': 'chat_history'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.memory.return_messages = True\n",
    "agent_chain.memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m, I'm looking for information about the coronavirus pandemic.\n",
      "\n",
      "RESPONSE\n",
      "--------------------\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Bing Search\",\n",
      "    \"action_input\": \"coronavirus pandemic\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<b>COVID-19</b> no longer represents a global health emergency, the World Health Organization said on Friday, a major if symbolic step towards the end of the <b>pandemic</b> that has killed more than 6.9 ...\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 5 column 1 (char 160)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_chain\u001b[39m.\u001b[39;49mrun(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mHi There!, my name is Mutaz\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\chains\\base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    241\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m but not both. Got args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\chains\\base.py:140\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    141\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\chains\\base.py:134\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    128\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    129\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    130\u001b[0m     inputs,\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 134\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    135\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    136\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    139\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\agents\\agent.py:905\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 905\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m    906\u001b[0m         name_to_tool_map,\n\u001b[0;32m    907\u001b[0m         color_mapping,\n\u001b[0;32m    908\u001b[0m         inputs,\n\u001b[0;32m    909\u001b[0m         intermediate_steps,\n\u001b[0;32m    910\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m    911\u001b[0m     )\n\u001b[0;32m    912\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    913\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m    914\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m    915\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\agents\\agent.py:749\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors:\n\u001b[1;32m--> 749\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    750\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(e)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m    751\u001b[0m     observation \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInvalid or incomplete response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\agents\\agent.py:742\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \n\u001b[0;32m    738\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    741\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 742\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mplan(\n\u001b[0;32m    743\u001b[0m         intermediate_steps,\n\u001b[0;32m    744\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    745\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[0;32m    746\u001b[0m     )\n\u001b[0;32m    747\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    748\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\agents\\agent.py:426\u001b[0m, in \u001b[0;36mAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    424\u001b[0m full_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    425\u001b[0m full_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_chain\u001b[39m.\u001b[39mpredict(callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse(full_output)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\agents\\conversational_chat\\output_parser.py:28\u001b[0m, in \u001b[0;36mConvoOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     26\u001b[0m     cleaned_output \u001b[39m=\u001b[39m cleaned_output[: \u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m     27\u001b[0m cleaned_output \u001b[39m=\u001b[39m cleaned_output\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m---> 28\u001b[0m response \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(cleaned_output)\n\u001b[0;32m     29\u001b[0m action, action_input \u001b[39m=\u001b[39m response[\u001b[39m\"\u001b[39m\u001b[39maction\u001b[39m\u001b[39m\"\u001b[39m], response[\u001b[39m\"\u001b[39m\u001b[39maction_input\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m action \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFinal Answer\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\py_openai_flask\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\ProgramData\\Miniconda3\\envs\\py_openai_flask\\lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 5 column 1 (char 160)"
     ]
    }
   ],
   "source": [
    "agent_chain.run(input='Hi There!, my name is Mutaz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`run` not supported when there is not exactly one output key. Got ['output', 'intermediate_steps'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m agent_chain\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mwhat are some good dinners to make this week, if i like thai food?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\langchain\\chains\\base.py:228\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m\"\"\"Run the chain as text in, text out or multiple variables, text out.\"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`run` not supported when there is not exactly \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mone output key. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs:\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: `run` not supported when there is not exactly one output key. Got ['output', 'intermediate_steps']."
     ]
    }
   ],
   "source": [
    "agent_chain.run(\"what are some good dinners to make this week, if i like thai food?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding math tool to the agent \n",
    "\n",
    "https://python.langchain.com/en/latest/modules/agents/getting_started.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.load_tools import _get_llm_math, _get_bing_search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_maths = []\n",
    "# tools_maths.append(\"llm-math\")\n",
    "tools_maths.append(_get_llm_math(llm=azure_llm))\n",
    "# tools_maths.append(\n",
    "#     Tool(\n",
    "#         name=\"Intermediate Answer\",\n",
    "#         func=search.run,\n",
    "#         description=\"useful for when you need to ask with search\", \n",
    "\n",
    "#     )\n",
    "# )\n",
    "tools_maths.append(_get_bing_search(bing_subscription_key=bing_subscription_key, bing_search_url=bing_search_url, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Calculator', description='Useful for when you need to answer questions about math.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, func=<bound method Chain.run of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=AzureOpenAI(cache=None, verbose=True, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={'api_base': 'https://magopenai.openai.azure.com/', 'api_type': 'azure', 'api_version': '2023-03-15-preview'}, openai_api_key='4a3eda50f0f444cd8baefc46f45ea61a', openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', deployment_name='text-davinci-003'), output_key='text'), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')>, coroutine=<bound method Chain.arun of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=AzureOpenAI(cache=None, verbose=True, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.0, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={'api_base': 'https://magopenai.openai.azure.com/', 'api_type': 'azure', 'api_version': '2023-03-15-preview'}, openai_api_key='4a3eda50f0f444cd8baefc46f45ea61a', openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', deployment_name='text-davinci-003'), output_key='text'), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')>),\n",
      " BingSearchRun(name='Bing Search', description='A wrapper around Bing Search. Useful for when you need to answer questions about current events. Input should be a search query.', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, api_wrapper=BingSearchAPIWrapper(bing_subscription_key='0058d1f5e71c49b6ae96fc3155db5789', bing_search_url='https://api.bing.microsoft.com/v7.0/search', k=1))]\n"
     ]
    }
   ],
   "source": [
    "pprint(tools_maths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_maths_agent = initialize_agent(\n",
    "    tools_maths, \n",
    "    azure_llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_maths_agent = initialize_agent(\n",
    "#     [_get_llm_math(llm=azure_llm), \n",
    "#      Tool(\n",
    "#         name=\"Intermediate Answer\",\n",
    "#         func=search.run,\n",
    "#         description=\"useful for when you need to ask with search\",)], \n",
    "#     azure_llm, \n",
    "#     agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "#     verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the height of Barack Obama and the age of Hillary Clinton\n",
      "Action: Bing Search\n",
      "Action Input: \"Barack Obama height\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<b>Barack</b> <b>Obama</b>: 6 ft 1 + 1 ... The largest <b>height</b> difference between two presidential candidates (out of the candidates whose heights are known) was in the 1860 election, when Abraham Lincoln stood 12 inches (30 cm) taller than opponent Stephen A. Douglas.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out the age of Hillary Clinton\n",
      "Action: Bing Search\n",
      "Action Input: \"Hillary Clinton age\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mt. e. <b>Hillary</b> Diane Rodham <b>Clinton</b> (born October 26, 1947) is an American politician and diplomat who served as the 67th United States secretary of state under president Barack Obama from 2009 to 2013, as a United States senator representing New York from 2001 to 2009, and as the first lady of the United States as the wife of President Bill ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 73 cm\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'73 cm'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run(\"What is the height Barack Obama in cm devided by two and then added to Hillary Clinton's age?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_ask_with_search.run('What is the height Barack Obama in cm ?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_ask_with_search.run('what is Hillary Clinton\\'s age?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.5"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(185 / 2) + 73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self_ask_with_search.run('what is the Population of Australia? and what is it\\'s Area?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the population and total area of Australia\n",
      "Action: Bing Search\n",
      "Action Input: \"population of Australia\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn 2021, 29.1% <b>of Australia</b>&#39;s <b>population</b> were born overseas. This decreased from 29.8% in 2020 ; 7.5 million people resident in <b>Australia</b> in 2021 were born overseas; Largest group of overseas-born were born in England, however Indian-born was the group with the largest increase since 2011\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find the total area of Australia\n",
      "Action: Bing Search\n",
      "Action Input: \"total area of Australia\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mIn addition to the mainland, <b>Australia</b> is surrounded by many thousands of small fringing islands and numerous larger ones, which, overall, amount to an <b>area</b> half the size of Tasmania. State/Territory. %. Mainland <b>area</b> km 2. Island <b>area</b> km 2. <b>Total</b> <b>area</b> km 2. Western <b>Australia</b>. 32.9. 2 523 924.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the population and total area of Australia\n",
      "Action: Calculator\n",
      "Action Input: 7.5 million people / 2 523 924 km2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 2.972651605231867\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: On average, there are 2.97 km2 per person in Australia.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'On average, there are 2.97 km2 per person in Australia.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run(\"In Australia, how many km2 per person on average ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to divide a large number by a smaller number\n",
      "Action: Calculator\n",
      "Action Input: 7,682,300 Km2 / 26,124,814\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 0.29406142374831834\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 0.29406142374831834 Km2 per person\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.29406142374831834 Km2 per person'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run(\"what is 7,682,300 Km2 / 26,124,814 people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29406142374831834"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7682300/26124814\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new way for bing and maths \n",
    "\n",
    "new_tools2  = [] \n",
    "new_tools2.append(_get_llm_math(llm=azure_llm))\n",
    "new_tools2.append(_get_bing_search(\n",
    "    bing_search_url= bing_search_url,\n",
    "    bing_subscription_key=bing_subscription_key))\n",
    "\n",
    "\n",
    "\n",
    "new_maths_agent2 = initialize_agent(\n",
    "    new_tools2, \n",
    "    azure_llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to calculate the area of Australia first.\n",
      "Action: Intermediate Answer\n",
      "Action Input: Area of Australia in km2\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<b>Australia</b>. / ﻿ 35.30806°S 149.12444°E ﻿ / -35.30806; 149.12444. <b>Australia</b>, officially the Commonwealth of <b>Australia</b>, is a sovereign country comprising the mainland of the Australian continent, the island of Tasmania, and numerous smaller islands. [14] <b>Australia</b> is the largest country by <b>area</b> in Oceania and the world&#39;s sixth-largest country. In addition to the mainland, <b>Australia</b> is surrounded by many thousands of small fringing islands and numerous larger ones, which, overall, amount to an <b>area</b> half the size of Tasmania. State/Territory. %. Mainland <b>area</b> <b>km 2</b>. Island <b>area</b> <b>km 2</b>. Total <b>area</b> <b>km 2</b>. Western <b>Australia</b>. 32.9. 2 523 924. This is a list of countries by total <b>area</b>. The total <b>area</b> is the sum of all land and Inland water bodies (lakes, reservoirs, rivers). Data is taken from the United Nations Statistics Division. Pos Country Total <b>in km 2</b> (mi 2) 1 ... <b>Australia</b>: 7,692,024 (2,969,907) 7 Covering an <b>area</b> of 7,617,930 sq.km (2,969,907 sq mi), <b>Australia</b> is the smallest continent, the world’s 6 th largest country and the largest country in Oceania. It is located between the Indian and Pacific Oceans in the Southern hemisphere. <b>Australia</b> is extremely dry, with about 35% of the country receiving very little rain (if any). Land <b>area</b> (sq. km) in <b>Australia</b> was reported at 7692020 sq. Km in 2021, according to the World Bank collection of development indicators, compiled from officially recognized sources. <b>Australia</b> - Land <b>area</b> (sq. km) - actual values, historical data, forecasts and projections were sourced from the &#39;&gt;World Bank&lt;/a&gt; on May of 2023. The land <b>area</b> of <b>Australia</b> is 7,682,300 <b>km2</b> and accounts for only 5 % of the world’s land <b>area</b> of 149 450 000 square km.; Over 85 percent of Australian’s live less than 50 kilometers from the coast, not surprising then that beaches are an integral part of Australian life, the East Coast being one of the most popular areas. <b>Australia</b> is the planet’s sixth-largest country after Russia ... David Whitley. 16/07/2021. Practicalities. The size of Queensland, <b>Australia</b>, is enormous. The <b>area</b> of Queensland is 1,729,742 square kilometres, which makes the Australian state bigger than Iran or Alaska. Queensland is <b>Australia</b>’s second largest state, and it has an incredibly long coastline. Most imagine that travelling from Brisbane to ... This image shows the location of <b>Australia</b>’s centre of population on a map of <b>Australia</b>. The <b>area</b> of the centre of population is zoomed in to an SA2 level, showing the locations of the centre of population as at 30 June 2021 and 30 June 2022. These locations are in Far West SA2, north of Hay SA2 in NSW.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the area of Australia, so I can calculate the answer to the original question.\n",
      "Action: Calculator\n",
      "Action Input: 1.5 * 7692020\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 11538030.0\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: 11538030.0 km2\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'11538030.0 km2'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run('What is 1.5 times area of Australia in km2?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to know the current population of Australia\n",
      "Action: Intermediate Answer\n",
      "Action Input: Current population of Australia\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mStatistics in this release are commonly known as Estimated Resident <b>Population</b> (ERP). <b>Australia</b>’s <b>population</b> was 26,124,814 people at 30 September 2022. The quarterly growth was 128,670 people (0.5%). The annual growth was 418,500 people (1.6%). Annual natural increase was 114,800 and net overseas migration was 303,700. The 2021 Census counted 25,422,788 people in <b>Australia</b> (excludes overseas visitors), an increase of 8.6 per cent since the 2016 Census. 49.3 per cent of the <b>population</b> were male with a median age of 37 years old. 50.7 per cent of the <b>population</b> were female with the median age of 39 years old. Image. The <b>current population of Australia</b> is 26,336,160 as of Wednesday, May 3, 2023, based on <b>Worldometer</b> elaboration of the latest United Nations data. <b>Australia</b> 2020 <b>population</b> is estimated at 25,499,884 people at mid year according to UN data. <b>Australia population</b> is equivalent to 0.33% of the total world <b>population</b>. Statistics in this release are commonly known as Estimated Resident <b>Population</b> (ERP). <b>Australia</b>’s <b>population</b> was 26,124,814 people at 30 September 2022. The quarterly growth was 128,670 people (0.5%). The annual growth was 418,500 people (1.6%). Annual natural increase was 114,800 and net overseas migration was 303,700. 26,462,247. This projection is based on the estimated resident <b>population</b> at 30 September 2022 and assumes growth since then of: one birth every 1 minute and 43 seconds, one death every 3 minutes and 10 seconds, one person arriving to live in <b>Australia</b> every 44 seconds, one Australian resident leaving <b>Australia</b> to live overseas every 1 minute ... Census media hub. Providing the latest 2021 Census media releases, information and resources. After losing <b>population</b> during the COVID-19 pandemic, the capitals grew by 205,400 people (1.2%) in 2021-22. Capital city growth comprised overseas migration (151,400), natural increase (101,200) and internal migration (-47,200). Brisbane had the largest increase (59,200) and the highest growth rate (2.3%). Regional <b>Australia</b> grew by 102,700 (1 ... <b>Australia</b>, the smallest continent and one of the largest countries on Earth, lying between the Pacific and Indian oceans in the Southern Hemisphere. <b>Australia</b>’s capital is Canberra, located in the southeast between the larger and more important economic and cultural centres of Sydney and Melbourne. The Australian mainland extends from west to east for nearly 2,500 miles (4,000 km) and from ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the current population of Australia\n",
      "Action: Calculator\n",
      "Action Input: 26,336,160 x 2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 52672320\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The population of Australia, if it is doubled, will be 52,672,320.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The population of Australia, if it is doubled, will be 52,672,320.'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run('If ausralias population is doubled, what will the population be?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what version of the library is available\n",
      "Action: Intermediate Answer\n",
      "Action Input: \"langchain python library version\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<b>LangChain</b> provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents. 🧠 Memory: Memory refers to persisting state between calls of a chain/agent. <b>LangChain</b> provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory. Welcome to <b>LangChain</b>. #. <b>LangChain</b> is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data. Be agentic: allow a language model to ... <b>LangChain</b> provides many modules that can be used to build language model applications. ... A function that performs a specific duty. This can be things like: Google Search, Database lookup, <b>Python</b> REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an ... To install modules needed for the common LLM providers, run: pip install <b>langchain</b>[llms] To install all modules needed for all integrations, run: pip install <b>langchain</b>[all] Note that if you are using zsh, you’ll need to quote square brackets when passing them as an argument to a command, for example: pip install &#39;<b>langchain</b> [all]&#39;. Before installing the <b>langchain</b> package, ensure you have a <b>Python</b> <b>version</b> of ≥ 3.8.1 and &lt;4.0. To install the <b>langchain</b> <b>Python</b> package, you can pip install it. ... <b>LangChain</b> is an open-source <b>Python</b> <b>library</b> that enables anyone who can write code to build LLM-powered applications. The package provides a generic interface to many ... pydantic model <b>langchain</b>.utilities. ... - Install the <b>library</b> using pip install google-api-<b>python</b>-client The current <b>version</b> of the <b>library</b> is 2.70.0 at this time. 2. To create an API key: - Navigate to the APIs &amp; Services→Credentials panel in Cloud Console. - Select Create credentials, then select API key from the drop-down menu. <b>LangChain</b> is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: Be data-aware: connect a language model to other sources of data. Be agentic: Allow a language model to interact with its ... Note 1: We must regard the <b>Python</b> <b>version</b>. If we have installed different versions of <b>Python</b>, we have to open the terminal in the <b>Python</b> <b>version</b> we are interested in. For example, opening the terminal with <b>Python</b> 3.8 can (surely will) give a different <b>version</b> of a <b>library</b> than opening with <b>Python</b> 3.5 or <b>Python</b> 2.7. Installation and Setup #. Install the <b>Python</b> SDK with pip install openai. Get an OpenAI api key and set it as an environment variable ( OPENAI_API_KEY) If you want to use OpenAI’s tokenizer (only available for <b>Python</b> 3.9+), install it with pip install tiktoken.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The current version of the LangChain Python library is 2.70.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current version of the LangChain Python library is 2.70.0.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_maths_agent.run('what is the version of langchain python library?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Yes.\n",
      "Follow up: What is langchain?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3m<b>LangChain</b>. At its core, <b>LangChain</b> is a framework built around LLMs. We can use it for chatbots, Generative Question-Answering (GQA), summarization, and much more. The core idea of the library is that we can “chain” together different components to create more advanced use cases around LLMs. Chains may consist of multiple components from several modules: <b>LangChain</b> is a software development framework designed to simplify the creation of applications using large language models (LLMs). Background. <b>LangChain</b> was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. <b>LangChain</b> is a standard interface through which you can interact with a variety of LLMs. Prompt templates; <b>LangChain</b> provides several classes and functions to make constructing and working with prompts easy. Memory; <b>LangChain</b> provides memory components to manage and manipulate previous chat messages and incorporate them into chains. <b>LangChain</b> is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also: Be data-aware: connect a language model to other sources of data. Be agentic: Allow a language model to interact with its ... <b>What is LangChain</b>? <b>LangChain</b> is a framework built to help you build LLM-powered applications more easily by providing you with the following: a generic interface to a variety of different foundation models (see Models),; a framework to help you manage your prompts (see Prompts), and; a central interface to long-term memory (see Memory), external data (see Indexes), other LLMs (see Chains), and ... Welcome to <b>LangChain</b>. #. <b>LangChain</b> is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data. Be agentic: allow a language model to ... <b>LangChain</b> is a library that helps developers build applications powered by large language models (LLMs). It does this by providing a framework for connecting LLMs to other sources of data, such as ... <b>What is LangChain</b>? <b>LangChain</b> is an open-source library that provides developers with the tools to build applications powered by large language models (LLMs). More specifically, <b>LangChain</b> is an orchestration tool for prompts, making it easier for developers to chain different prompts interactively.\u001b[0m\u001b[32;1m\u001b[1;3mFollow up: What version is the langchain python library?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3m<b>LangChain</b> provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents. 🧠 Memory: Memory refers to persisting state between calls of a chain/agent. <b>LangChain</b> provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory. Welcome to <b>LangChain</b>. #. <b>LangChain</b> is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware: connect a language model to other sources of data. Be agentic: allow a language model to ... pydantic model <b>langchain</b>.utilities. ... - Install the <b>library</b> using pip install google-api-<b>python</b>-client The current <b>version</b> of the <b>library</b> is 2.70.0 at this time. 2. To create an API key: - Navigate to the APIs &amp; Services→Credentials panel in Cloud Console. - Select Create credentials, then select API key from the drop-down menu. <b>LangChain</b> provides many modules that can be used to build language model applications. ... A function that performs a specific duty. This can be things like: Google Search, Database lookup, <b>Python</b> REPL, other chains. The interface for a tool is currently a function that is expected to have a string as an input, with a string as an ... Before installing the <b>langchain</b> package, ensure you have a <b>Python</b> <b>version</b> of ≥ 3.8.1 and &lt;4.0. To install the <b>langchain</b> <b>Python</b> package, you can pip install it. ... <b>LangChain</b> is an open-source <b>Python</b> <b>library</b> that enables anyone who can write code to build LLM-powered applications. The package provides a generic interface to many ... By default, the dependencies needed to do that are NOT installed. However, there are two other ways to install <b>LangChain</b> that do bring in those dependencies. To install modules needed for the common LLM providers, run: pip install <b>langchain</b>[llms] To install all modules needed for all integrations, run: pip install <b>langchain</b>[all] Note 1: We must regard the <b>Python</b> <b>version</b>. If we have installed different versions of <b>Python</b>, we have to open the terminal in the <b>Python</b> <b>version</b> we are interested in. For example, opening the terminal with <b>Python</b> 3.8 can (surely will) give a different <b>version</b> of a <b>library</b> than opening with <b>Python</b> 3.5 or <b>Python</b> 2.7. LLM #. There exists an OpenAI LLM wrapper, which you can access with. from <b>langchain</b>.llms import OpenAI. If you are using a model hosted on Azure, you should use different wrapper for that: from <b>langchain</b>.llms import AzureOpenAI. For a more detailed walkthrough of the Azure wrapper, see this notebook.\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: 2.70.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.70.0'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ask_with_search.run('what is the version of langchain python library?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_openai_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
