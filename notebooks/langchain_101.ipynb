{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_endpoint: https://lnc-eastus-openai.openai.azure.com/\n",
      "gpt4_key: **********\n",
      "gpt4_region: eastus\n",
      "gpt4_modelid_4k: gpt-4-0314\n",
      "gpt4_modelid_32k: gpt-4-32k-0314\n",
      "gpt4_api_version: 2023-03-15-preview\n",
      "chatgpt_api_key: **********\n",
      "chatgpt_region: southcentralus\n",
      "chatgpt_endpoint: https://magopenai.openai.azure.com/\n",
      "oai_api_key: **********\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import utils.openai_env as oai_env\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# get above env variables using os.environ.get and use provided values as defaults\n",
    "gpt4_endpoint = os.environ.get('gpt4_endpoint', 'https://lnc-eastus-openai.openai.azure.com/')\n",
    "gpt4_key = os.environ.get('gpt4_key', '121221')\n",
    "gpt4_region = os.environ.get('gpt4_region', 'eastus')\n",
    "gpt4_modelid_4k = os.environ.get('gpt4_modelid_4k', 'gpt-4-0314')\n",
    "gpt4_modelid_32k = os.environ.get('gpt4_modelid_32k', 'gpt-4-32k-0314')\n",
    "gpt4_api_version = os.environ.get('gpt4_api_version', '2023-03-15-preview')\n",
    "\n",
    "\n",
    "# get the above from os.environ.get and use provided values as defaults\n",
    "chatgpt_api_key = os.environ.get('chatgpt_api_key', '121212121212')\n",
    "chatgpt_region = os.environ.get('chatgpt_region', 'southcentralus')\n",
    "chatgpt_endpoint = os.environ.get('chatgpt_endpoint', 'https://magopenai.openai.azure.com/')\n",
    "\n",
    "oai_api_key = os.environ.get('oai_api_key', '121212121212')\n",
    "\n",
    "print(f'gpt4_endpoint: {gpt4_endpoint}')\n",
    "print(f'gpt4_key: **********')\n",
    "print(f'gpt4_region: {gpt4_region}')\n",
    "print(f'gpt4_modelid_4k: {gpt4_modelid_4k}')\n",
    "print(f'gpt4_modelid_32k: {gpt4_modelid_32k}')\n",
    "print(f'gpt4_api_version: {gpt4_api_version}')\n",
    "print(f'chatgpt_api_key: **********')\n",
    "print(f'chatgpt_region: {chatgpt_region}')\n",
    "print(f'chatgpt_endpoint: {chatgpt_endpoint}')\n",
    "print(f'oai_api_key: **********')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic text completion with a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: None\n",
      "openai.api_key: **********kKkw\n",
      "openai.api_base: https://api.openai.com/v1\n",
      "openai.api_type: open_ai\n",
      "openai.api_version: None\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/en/latest/reference/modules/llms.html#langchain.llms.AzureOpenAI\n",
    "\n",
    "from langchain import OpenAI\n",
    "# os.environ['OPENAI_API_KEY'] = oai_api_key\n",
    "llm = OpenAI(openai_api_key=oai_api_key, verbose=True)\n",
    "\n",
    "oai_env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTuesday.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What comes after Monday? \"\n",
    "llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"Question: {question}\\n\\n\"\n",
    "\"Answer:\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"],)\n",
    "\n",
    "question = \"once upon a time, in a galaxy far far away ... \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: once upon a time, in a galaxy far far away ... \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'once upon a time, in a galaxy far far away ... ', 'text': '\\nA long time ago, in a galaxy far, far away, there lived a wise and powerful Jedi Knight named Obi-Wan Kenobi. He was a great mentor and teacher to young Padawans, teaching them the ways of the Force and the Jedi Code. He was also a powerful warrior, able to wield a lightsaber with great skill and accuracy. Obi-Wan faced many battles and challenges during his lifetime, but he always managed to come out on top. He eventually passed away, but his legacy continued to live on throughout the galaxy.'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking Multiple Questions with LLM chain and generate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"What is the capital of Australia?\"},\n",
    "    {'question': \"Monday, Tuesday, ... ?\"},\n",
    "    {'question': \"what day of week is 33 of December 2019?\"},\n",
    "    {'question': \"is 33 of December 2019 a correct date?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the capital of Australia?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Monday, Tuesday, ... ?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: what day of week is 33 of December 2019?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: is 33 of December 2019 a correct date?\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The capital of Australia is Canberra.\n",
      "\n",
      "\n",
      "Answer: Wednesday, Thursday, Friday.\n",
      "\n",
      "Answer: Tuesday\n",
      "\n",
      "Answer: No, December 33rd does not exist. The last day of December is December 31st.\n"
     ]
    }
   ],
   "source": [
    "for r in res.generations:\n",
    "    print(r[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat Scenario \n",
    "#https://blog.langchain.dev/chat-models/ \n",
    "#https://python.langchain.com/en/latest/modules/chains/getting_started.html?highlight=chatopenai#query-an-llm-with-the-llmchain \n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI, ChatAzureOpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ChatOpenAI for basic chat prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY: None\n",
      "openai.api_key: **********kKkw\n",
      "openai.api_base: https://api.openai.com/v1\n",
      "openai.api_type: open_ai\n",
      "openai.api_version: None\n"
     ]
    }
   ],
   "source": [
    "https://python.langchain.com/en/latest/modules/models/chat/getting_started.html\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate, \n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import ( \n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "\n",
    "\n",
    "oai_env.print_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0, openai_api_key= openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime programmer.\", additional_kwargs={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to French. I love programming.\")\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
    "        HumanMessage(content=\"Translate this sentence from English to Arabic. I love artificial intelligence.\")\n",
    "    ],\n",
    "]\n",
    "result = chat.generate(batch_messages)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'aime programmer.\n",
      "-----\n",
      "أنا أحب الذكاء الاصطناعي.\n",
      "-----\n",
      "{'token_usage': {'prompt_tokens': 73, 'completion_tokens': 24, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# iterate over list of generations, unpack item number and generation item \n",
    "for i, generation in enumerate(result.generations):\n",
    "   \n",
    "    # iterate over list of messages in generation\n",
    "    for g in generation:\n",
    "        # print the message content\n",
    "        print(g.text)\n",
    "    # print a separator\n",
    "    print(\"-----\")\n",
    "\n",
    "\n",
    "\n",
    "print(result.llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Chat Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a distant galaxy far, far away, there was a planet called Zephyr, where strange creatures roamed and peculiar plants grew. There was one particular creature named Fizz, who was very different from his fellow beings.\n",
      "\n",
      "Fizz was a curious creature who had a giant head, tiny eyes, and no legs. Instead, he had a round body and many tentacles that acted as legs. He was always eager to explore the unknown and to discover new things.\n",
      "\n",
      "One day, while Fizz was wandering around, he stumbled upon a shiny object that looked like a spaceship. As he approached the object, he heard a strange beep sound coming from it. As he touched it, the spaceship came to life, and a holographic screen was activated.\n",
      "\n",
      "A voice emerged from the screen: \"Hello, Fizz. I have been waiting for you. I am Zorg, the spaceship, and I have been sent to take you on a mission.\"\n",
      "\n",
      "Fizz was thrilled and could not believe his ears. He did not know how to operate the spaceship, but Zorg took over and guided him through the controls.\n",
      "\n",
      "The spaceship took off, and Fizz felt an adrenaline rush as they sped through the galaxy. Zorg explained that they were on a critical mission to save the galaxy from an evil force that was trying to take over the planets.\n",
      "\n",
      "Fizz asked how he could help, and Zorg explained that they needed to collect special crystals that had the power to stop this evil force. They had to travel to different planets and find these crystals.\n",
      "\n",
      "Fizz was excited to help, and he and Zorg traveled to many different planets. They encountered various challenges along the way, but Fizz never gave up. He used his unique abilities to help Zorg and to overcome obstacles.\n",
      "\n",
      "Finally, after a long journey, they were able to collect all of the crystals they needed. They rushed to the planet that was under attack by the evil force, and Fizz and Zorg were able to use the crystals to defeat the evil force and save the galaxy.\n",
      "\n",
      "Fizz returned to his planet with a new appreciation for the power of teamwork and the importance of bravery. He knew that even though he was different, he could still make a difference and help his friends. From that day on, Fizz became a hero on his planet and throughout the galaxy."
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "chat_stream = ChatOpenAI(\n",
    "    openai_api_key=openai.api_key,\n",
    "    streaming=True, \n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), \n",
    "    verbose=True, \n",
    "    temperature=0)\n",
    "resp = chat_stream([HumanMessage(content=\"Write me a kids scifi story, starts with 'Once upon a time...'\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using prompt templates and chains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_dalle_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
