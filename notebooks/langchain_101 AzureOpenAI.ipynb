{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_endpoint: https://lnc-eastus-openai.openai.azure.com/\n",
      "gpt4_key: **********\n",
      "gpt4_region: eastus\n",
      "gpt4_modelid_4k: gpt-4-0314\n",
      "gpt4_modelid_32k: gpt-4-32k-0314\n",
      "gpt4_api_version: 2023-03-15-preview\n",
      "chatgpt_api_key: **********\n",
      "chatgpt_region: southcentralus\n",
      "chatgpt_endpoint: https://magopenai.openai.azure.com/\n",
      "oai_api_key: **********\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import langchain\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# get above env variables using os.environ.get and use provided values as defaults\n",
    "gpt4_endpoint = os.environ.get('gpt4_endpoint', 'https://lnc-eastus-openai.openai.azure.com/')\n",
    "gpt4_key = os.environ.get('gpt4_key', '121221')\n",
    "gpt4_region = os.environ.get('gpt4_region', 'eastus')\n",
    "gpt4_modelid_4k = os.environ.get('gpt4_modelid_4k', 'gpt-4-0314')\n",
    "gpt4_modelid_32k = os.environ.get('gpt4_modelid_32k', 'gpt-4-32k-0314')\n",
    "gpt4_api_version = os.environ.get('gpt4_api_version', '2023-03-15-preview')\n",
    "\n",
    "\n",
    "# get the above from os.environ.get and use provided values as defaults\n",
    "chatgpt_api_key = os.environ.get('chatgpt_api_key', '121212121212')\n",
    "chatgpt_region = os.environ.get('chatgpt_region', 'southcentralus')\n",
    "chatgpt_endpoint = os.environ.get('chatgpt_endpoint', 'https://magopenai.openai.azure.com/')\n",
    "\n",
    "oai_api_key = os.environ.get('oai_api_key', '121212121212')\n",
    "\n",
    "print(f'gpt4_endpoint: {gpt4_endpoint}')\n",
    "print(f'gpt4_key: **********')\n",
    "print(f'gpt4_region: {gpt4_region}')\n",
    "print(f'gpt4_modelid_4k: {gpt4_modelid_4k}')\n",
    "print(f'gpt4_modelid_32k: {gpt4_modelid_32k}')\n",
    "print(f'gpt4_api_version: {gpt4_api_version}')\n",
    "print(f'chatgpt_api_key: **********')\n",
    "print(f'chatgpt_region: {chatgpt_region}')\n",
    "print(f'chatgpt_endpoint: {chatgpt_endpoint}')\n",
    "print(f'oai_api_key: **********')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic text completion with a language model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using OpenAI model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "\n",
    "#https://python.langchain.com/en/latest/reference/modules/llms.html#langchain.llms.AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTuesday.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What comes after Monday? \"\n",
    "llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Azure OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_base = chatgpt_endpoint\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "\n",
    "azure_llm = AzureOpenAI(\n",
    "    deployment_name='text-davinci-003', \n",
    "    model_name='text-davinci-003', \n",
    "    openai_api_key=chatgpt_api_key,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nTuesday.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azure_llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"Question: {question}\\n\\n\"\n",
    "\"Answer:\"\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"question\"],)\n",
    "\n",
    "question = \"once upon a time, in a galaxy far far away ... \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=azure_llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: once upon a time, in a galaxy far far away ... \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'once upon a time, in a galaxy far far away ... ', 'text': '\\nA:\\n\\nThere lived a brave and noble warrior,\\nWhose courage and honor could not be deterred.\\nNo matter the danger, no matter the foe,\\nHe fought with a strength that could never be slowed.\\n\\nThrough valleys and forests and lands far away,\\nHe traveled the lands with his sword and his shield.\\nHe fought with a fervor, a spirit and zeal,\\nTo protect those in need and preserve what was real.\\n\\nThough his enemies feared his might and his rage,\\nHis heart was of pure and of honest intent.\\nFor he was a hero, a champion of light,\\nFighting for justice and a cause that was right.'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking Multiple Questions with LLM chain and generate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"What is the capital of Australia?\"},\n",
    "    {'question': \"Monday, Tuesday, ... ?\"},\n",
    "    {'question': \"what day of week is 33 of December 2019?\"},\n",
    "    {'question': \"is 33 of December 2019 a correct date?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is the capital of Australia?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Monday, Tuesday, ... ?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: what day of week is 33 of December 2019?\n",
      "\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mQuestion: is 33 of December 2019 a correct date?\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = llm_chain.generate(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: The capital of Australia is Canberra.\n",
      "\n",
      "\n",
      "Answer: Wednesday, Thursday, Friday.\n",
      "\n",
      "Answer: Tuesday\n",
      "\n",
      "Answer: No, December 33 does not exist. The last day of December 2019 is December 31.\n"
     ]
    }
   ],
   "source": [
    "for r in res.generations:\n",
    "    print(r[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat Scenario \n",
    "#https://blog.langchain.dev/chat-models/ \n",
    "#https://python.langchain.com/en/latest/modules/chains/getting_started.html?highlight=chatopenai#query-an-llm-with-the-llmchain \n",
    "\n",
    "# from langchain.chat_models import ChatOpenAI, ChatAzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_dalle_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
